{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Learning_Final_Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0gWaTxZYGIni"
      },
      "source": [
        "# Data Prep:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TPeJJjHy21FW",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio\n",
        "import skimage\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import re\n",
        "from copy import deepcopy\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w-jipBIYx2Wg"
      },
      "source": [
        "## Global Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z36UD2wC25Jl",
        "colab": {}
      },
      "source": [
        "PATH = \"src\" # Path where MovieGenre.csv $ /posters located\n",
        "NEW_SIZE = (44,30,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XypCgeQMyFWk"
      },
      "source": [
        "## Prep Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q6_KW8iYQjIM",
        "colab": {}
      },
      "source": [
        "def read_and_clean_data():\n",
        "    df = pd.read_csv(PATH + \"/MovieGenre.csv\", encoding=\"ISO-8859-1\", usecols=[\"imdbId\", \"Title\", \"Genre\", \"Poster\"])\n",
        "    df.set_index([\"imdbId\"], inplace=True)\n",
        "    print(f\"Shape of the original dataset: {df.shape}\")\n",
        "    df.dropna(inplace=True)\n",
        "    print(f\"Shape after dropping rows with missing values: {df.shape}\")\n",
        "    df.drop_duplicates(subset=\"Poster\", keep=False, inplace=True)\n",
        "    print(f\"Shape after dropping rows with potentially misleading poster link: {df.shape}\\n\")\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F2G96H_pRDOR",
        "colab": {}
      },
      "source": [
        "def get_genre_feature(genre):\n",
        "    return \"is_\" + re.sub(r'\\W+', '', genre.lower())\n",
        "\n",
        "def create_boolean_genres(df):\n",
        "    df[\"Genre\"] = df.Genre.map(lambda x: x.split(\"|\"))\n",
        "    all_genres = set([item for l in df.Genre for item in l])\n",
        "    filtered_genres = []\n",
        "    for genre in all_genres:\n",
        "        if len(movie_data[movie_data.Genre.apply(lambda genres: genre in genres)].index) < 2000 :\n",
        "            print(f\"{genre} was filtered out!\")\n",
        "            continue\n",
        "        filtered_genres.append(genre)\n",
        "        new_var = get_genre_feature(genre)\n",
        "        df[new_var] = df.Genre.map(lambda x: genre in x)\n",
        "\n",
        "    print(f\"\\nThere are {len(filtered_genres)} genres in the dataset: {filtered_genres}\\n\")    \n",
        "    df.drop([\"Genre\"], axis=1, inplace=True)\n",
        "    return filtered_genres"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j-oWWkBQCtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_year_variable(df):\n",
        "    re_year = re.compile(\"\\((\\d{4})\\)\")\n",
        "    df[\"Year\"] = df.Title.map(lambda x: int(re_year.findall(x)[0]) if re_year.findall(x) else 0)\n",
        "    print(f\"There are movies between {int(np.min(df.Year))} and {int(np.max(df.Year))} available in the dataset.\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8svec2wSQCtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_by_year(df, year):\n",
        "    new_df = df.loc[df.Year >= year]\n",
        "    return new_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y4Zs_UaBV2w_",
        "colab": {}
      },
      "source": [
        "movie_data = read_and_clean_data()\n",
        "add_year_variable(movie_data)\n",
        "movie_data = filter_by_year(movie_data, 2000)\n",
        "GENRES = create_boolean_genres(movie_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IImPL_rNg7FC",
        "colab": {}
      },
      "source": [
        "movie_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nrIhALU4aXay",
        "colab": {}
      },
      "source": [
        "movie_data.sort_index(inplace=True)\n",
        "movie_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cK5iaD40yRN7"
      },
      "source": [
        "## Get Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIyfvuDlQCtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(img):\n",
        "    return skimage.transform.resize(skimage.color.rgb2hsv(img), NEW_SIZE,  anti_aliasing=True,  preserve_range=True, mode='reflect')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dSQ4Ee4Snik4",
        "colab": {}
      },
      "source": [
        "# Add images via apply:\n",
        "def get_image(row):\n",
        "    image_path = PATH + \"/posters/{}.jpg\".format(row.name)\n",
        "    try:\n",
        "        img = preprocess_image(imageio.imread(image_path))\n",
        "        return img\n",
        "    except FileNotFoundError as e:\n",
        "        pass\n",
        "    except Exception as e:\n",
        "        print(\"Error in: \",row.name, \"\\n\" , e)\n",
        "        try:\n",
        "            img = imageio.imread(row.Poster)\n",
        "            imageio.imwrite(image_path, img)\n",
        "            img = preprocess_image(img)\n",
        "            print(\" -->  Fetched via Poster attribute\")\n",
        "            return img\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f8TbBCqVpf7w",
        "colab": {}
      },
      "source": [
        "movie_data.Poster = movie_data.apply(get_image, axis=1)\n",
        "print(\"DONE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i60TE_ZkQCt6",
        "colab_type": "text"
      },
      "source": [
        "## Create explenatory and dependent dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ss-UCDJmwqvX",
        "colab": {}
      },
      "source": [
        "movie_data.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y11k1OHQCt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for genre in GENRES:\n",
        "    print(f\"{genre} movies in the dataset: {sum(movie_data[get_genre_feature(genre)])}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDFSgPWEQCt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HDq1pRYQCuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poster_df = pd.DataFrame(movie_data.apply(lambda row: row.Poster.ravel() ,axis=1).tolist(), index=movie_data.index)\n",
        "genres_df = movie_data.drop([\"Poster\", \"Title\",\"Year\"], axis=1)\n",
        "poster_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBdpHMKyQCuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = list(movie_data.Poster.values)\n",
        "y = movie_data.iloc[:, 3:].values * 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vyITbzOFGMDq"
      },
      "source": [
        "# Baseline - Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWGQpUYBQCuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = KFold(n_splits=5)\n",
        "f1_scores = []\n",
        "for train_index, test_index in cv.split(poster_df, genres_df):\n",
        "    train_posters, test_posters, train_genres, test_genres = poster_df.iloc[train_index], poster_df.iloc[test_index], genres_df.iloc[train_index], genres_df.iloc[test_index]\n",
        "    models_dict = {genre:GaussianNB() for genre in GENRES}\n",
        "    model_pred = {}\n",
        "    model_scores = {}\n",
        "    for genre, model in models_dict.items():\n",
        "        genre_bool = get_genre_feature(genre)\n",
        "        model.fit(train_posters, train_genres[genre_bool])\n",
        "        model_pred[get_genre_feature(genre)] = model.predict(test_posters)\n",
        "\n",
        "\n",
        "    pred_df = pd.DataFrame(model_pred, index=test_genres.index).sort_index()\n",
        "    f1 = f1_score(y_true=test_genres, y_pred=pred_df, average='weighted')\n",
        "    f1_scores.append(f1)\n",
        "    \n",
        "print(f\"Average F1-score is: {np.mean(f1_scores)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa7GT1uXQCuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models_dict = {genre:GaussianNB() for genre in GENRES}\n",
        "train_posters, test_posters, train_genres, test_genres  = train_test_split(poster_df, genres_df)\n",
        "model_pred = {}\n",
        "model_proba = {}\n",
        "model_scores = {}\n",
        "for genre, model in models_dict.items():\n",
        "    genre_bool = get_genre_feature(genre)\n",
        "    model.fit(train_posters, train_genres[genre_bool])\n",
        "    model_pred[get_genre_feature(genre)] = model.predict(test_posters)\n",
        "    model_proba[genre] = model.predict_proba(test_posters)[:,1]\n",
        "    \n",
        "\n",
        "pred_df = pd.DataFrame(model_pred, index=test_genres.index).sort_index()\n",
        "proba_df = pd.DataFrame(model_proba, index=test_genres.index).sort_index().round(3)\n",
        "f1 = f1_score(y_true=test_genres, y_pred=pred_df, average='weighted', )\n",
        "print(f\"Weighted F1-score is: {f1}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qPko7PEIGGWF"
      },
      "source": [
        "# Basic ,Advanced and Creative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AnW1dPpRGg3E",
        "colab": {}
      },
      "source": [
        "## Aux functions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkKyhFUWQCuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_params(params, r):\n",
        "    new_params = []\n",
        "    ss = np.sqrt(sum([np.sum(x * x) for x in params]))\n",
        "    for param in params:\n",
        "        new_params.append(param * (r / ss))\n",
        "    return new_params\n",
        "\n",
        "def get_features(img_block):\n",
        "    return img_block.ravel()\n",
        " \n",
        "    \n",
        "def normalize_factor(factor):\n",
        "    return factor / np.sum(factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHMXIAvQQCuZ",
        "colab_type": "text"
      },
      "source": [
        "## Cluster and ClusterGraph classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA0nBFZ9QCua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cluster:\n",
        "    def __init__(self,cluster_type, num_hidden, params=None, loc=None, genre_prior=0.5, is_ver=None, is_creative=False):\n",
        "        self.loc = loc\n",
        "        self.params = params\n",
        "        self.type = cluster_type\n",
        "        self.is_creative = is_creative\n",
        "        self.is_ver = is_ver\n",
        "        if cluster_type == 'y':\n",
        "            self.pot = np.array([1-genre_prior, genre_prior] )\n",
        "        elif cluster_type == 'hy':\n",
        "            self.pot = np.exp(self.params[1])\n",
        "        elif cluster_type == 'hhy':\n",
        "            self.pot = np.exp(self.params[2] + self.params[3][self.is_ver])\n",
        "        elif cluster_type == 'h': \n",
        "            self.pot = None\n",
        "        \n",
        "        self.messages = {}\n",
        "        self.prev_messages = {}\n",
        "        self.original_messages = {}\n",
        "        self.neighbors = {}\n",
        "        self.belief = None\n",
        "    \n",
        "    \n",
        "    def set_params(self, params):\n",
        "        self.params = params\n",
        "        if self.type == 'hy':\n",
        "            self.pot = np.exp(self.params[1])\n",
        "        elif self.type == 'hhy':\n",
        "            self.pot = np.exp(self.params[2] + self.params[3][self.is_ver])\n",
        "    \n",
        "    \n",
        "    def set_pot_X(self, img_block):\n",
        "        self.pot = np.exp(self.params[0] @ get_features(img_block))\n",
        "    \n",
        "    \n",
        "    def set_pot_y(self, y):\n",
        "        self.pot = self.pot[y]\n",
        "    \n",
        "    \n",
        "    def add_neighbor(self, neighbor, messages, neighbor_type, loc=None):\n",
        "        if neighbor_type == 'y':\n",
        "            self.messages['y'] = deepcopy(messages)\n",
        "            self.prev_messages['y'] = deepcopy(messages)\n",
        "            self.original_messages['y'] = deepcopy(messages)\n",
        "            self.neighbors['y'] = neighbor\n",
        "        else:\n",
        "            self.messages[(neighbor_type, loc)] = deepcopy(messages)\n",
        "            self.prev_messages[(neighbor_type, loc)] = deepcopy(messages)\n",
        "            self.original_messages[(neighbor_type, loc)] = deepcopy(messages)\n",
        "            self.neighbors[(neighbor_type, loc)] = neighbor\n",
        "    \n",
        "    \n",
        "    def reset_messages(self):\n",
        "        self.prev_messages = deepcopy(self.original_messages)\n",
        "        self.messages = deepcopy(self.original_messages)\n",
        "        self.belief = None\n",
        "    \n",
        "    \n",
        "    def calculate_belief(self, is_y_None):\n",
        "        belief = self.pot\n",
        "        if self.type == 'h':\n",
        "            for neighbor in self.neighbors.values():\n",
        "                belief = belief * neighbor.messages[('h', self.loc)]\n",
        "        if is_y_None:\n",
        "            if self.type == 'y':\n",
        "                for neighbor in self.neighbors.values():\n",
        "                    belief = belief * neighbor.messages['y']\n",
        "            elif self.type == 'hy':\n",
        "                for neighbor in self.neighbors.values():\n",
        "                    if neighbor.type == 'y':\n",
        "                        belief = belief * neighbor.messages[('hy', self.loc)][:, None]\n",
        "                    else:\n",
        "                        belief = belief * neighbor.messages[('hy', self.loc)][None, :]\n",
        "            elif self.type == 'hhy':\n",
        "                for neighbor in self.neighbors.values():\n",
        "                    if neighbor.type == 'y':\n",
        "                        belief = belief * neighbor.messages[('hhy', self.loc)][:, None, None]\n",
        "                    else:\n",
        "                        loc1, loc2 = self.loc\n",
        "                        if neighbor.loc == loc1:\n",
        "                            belief = belief * neighbor.messages[('hhy', self.loc)][None, :, None]\n",
        "                        elif neighbor.loc == loc2:\n",
        "                            belief = belief * neighbor.messages[('hhy', self.loc)][None, None, :]\n",
        "        else:\n",
        "            if self.type == 'hy':\n",
        "                for neighbor in self.neighbors.values():\n",
        "                    if neighbor.type != 'y':\n",
        "                        belief = belief * neighbor.messages[('hy', self.loc)]\n",
        "            elif self.type == 'hhy':\n",
        "                for neighbor in self.neighbors.values():\n",
        "                    if neighbor.type != 'y':\n",
        "                        loc1, loc2 = self.loc\n",
        "                        if neighbor.loc == loc1:\n",
        "                            belief = belief * neighbor.messages[('hhy', self.loc)][:, None]\n",
        "                        elif neighbor.loc == loc2:\n",
        "                            belief = belief * neighbor.messages[('hhy', self.loc)][None, :]\n",
        "        self.belief = normalize_factor(belief)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TKSkJ9WQCub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClusterGraph:\n",
        "    def __init__(self, img_size, num_blocks, num_hidden, est_type, genre_prior, num_classes):\n",
        "        self.liklihood = 0\n",
        "        self.genre_prior = genre_prior\n",
        "        self.est_type = est_type\n",
        "        self.is_creative = (self.est_type == 'Creative')\n",
        "        self.block_size = tuple(int(img_size[i] / num_blocks[i]) for i in range(2))\n",
        "        self.num_features = 3 * self.block_size[0] * self.block_size[1] # RGB for each pixel\n",
        "        self.img_size = img_size\n",
        "        self.num_blocks = num_blocks\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_classes = num_classes\n",
        "        self.params = [np.random.normal(0, 10, (self.num_hidden, self.num_features)), np.random\n",
        "                       .normal(0, 10, (self.num_classes, self.num_hidden)), np.random.normal(0, 10, (self.num_classes, self.num_hidden, self.num_hidden)), np.zeros((2, self.num_classes, self.num_hidden, self.num_hidden))]        \n",
        "            \n",
        "        clusters = {'h':{}, 'hy':{}, 'hhy':{}}\n",
        "        clusters['y'] = Cluster('y', num_hidden, genre_prior=genre_prior)\n",
        "        self.all_clusters = set()\n",
        "        self.all_clusters.add(clusters['y'])\n",
        "        for i in range(num_blocks[0]):\n",
        "            for j in range(num_blocks[1]):\n",
        "                loc1 = (i, j)\n",
        "                clusters['h'][loc1] = Cluster('h', num_hidden, self.params, loc1)\n",
        "                clusters['hy'][loc1] = Cluster('hy', num_hidden, self.params, loc1)  \n",
        "                if j != num_blocks[1] - 1:\n",
        "                    loc2 = (i, j + 1)\n",
        "                    clusters['hhy'][(loc1, loc2)] = Cluster('hhy', num_hidden, self.params, (loc1, loc2), is_ver=0)\n",
        "                if i != num_blocks[0] - 1:\n",
        "                    loc2 = (i + 1, j)\n",
        "                    clusters['hhy'][(loc1, loc2)] = Cluster('hhy', num_hidden, self.params, (loc1, loc2), is_ver=1)\n",
        "        for loc in clusters['hy'].keys():\n",
        "            clusters['y'].add_neighbor(clusters['hy'][loc], np.ones(self.num_classes), 'hy', loc)\n",
        "            clusters['hy'][loc].add_neighbor(clusters['y'], np.ones(self.num_classes), 'y')\n",
        "            clusters['h'][loc].add_neighbor(clusters['hy'][loc], np.ones(self.num_hidden), 'hy', loc)\n",
        "            clusters['hy'][loc].add_neighbor(clusters['h'][loc], np.ones(self.num_hidden), 'h', loc)\n",
        "        for loc1, loc2 in clusters['hhy'].keys():\n",
        "            clusters['y'].add_neighbor(clusters['hhy'][(loc1, loc2)], np.ones(self.num_classes), 'hhy', (loc1, loc2))\n",
        "            clusters['hhy'][(loc1, loc2)].add_neighbor(clusters['y'], np.ones(self.num_classes), 'y')\n",
        "            clusters['h'][loc1].add_neighbor(clusters['hhy'][(loc1, loc2)], np.ones(self.num_hidden), 'hhy', (loc1, loc2))\n",
        "            clusters['h'][loc2].add_neighbor(clusters['hhy'][(loc1, loc2)], np.ones(self.num_hidden), 'hhy', (loc1, loc2))\n",
        "            clusters['hhy'][(loc1, loc2)].add_neighbor(clusters['h'][loc1], np.ones(self.num_hidden), 'h', loc1)\n",
        "            clusters['hhy'][(loc1, loc2)].add_neighbor(clusters['h'][loc2], np.ones(self.num_hidden), 'h', loc2)\n",
        "        self.clusters = clusters\n",
        "        \n",
        "        for cluster_type in ['h', 'hy', 'hhy']:\n",
        "            for cluster in self.clusters[cluster_type].values():\n",
        "                self.all_clusters.add(cluster)        \n",
        "     \n",
        "    \n",
        "    def reset_messages(self):\n",
        "        for cluster in self.all_clusters:\n",
        "            cluster.reset_messages()\n",
        "    \n",
        "    \n",
        "    def set_params(self, params):\n",
        "        self.params = params\n",
        "        for cluster in self.all_clusters:\n",
        "            cluster.set_params(params)\n",
        "    \n",
        "    \n",
        "    def update_prev_messages(self):\n",
        "        for cluster in self.all_clusters:\n",
        "            cluster.prev_messages = deepcopy(cluster.messages)   \n",
        "\n",
        "\n",
        "    def convert_to_blocks(self, image):\n",
        "        row_blocks = np.split(image, self.num_blocks[0], axis=0)\n",
        "        blocks = [np.split(row_block, self.num_blocks[1], axis=1) for row_block in row_blocks]\n",
        "        return blocks\n",
        "        \n",
        "        \n",
        "    def gradient_ascent(self, X, y, size, num_LBP_iterations, num_GD_iterations):\n",
        "        for t in range(num_GD_iterations):\n",
        "            step_size = 2 / (t + 1)\n",
        "            new_params = deepcopy(self.params)\n",
        "            grad = self.gradient(X, y, size, num_LBP_iterations)\n",
        "            \n",
        "            for j in range(4):\n",
        "                new_params[j] += step_size * grad[j]\n",
        "            self.set_params(normalize_params(new_params, 1))\n",
        "    \n",
        "        \n",
        "    def gradient(self, X, y, size, num_LBP_iterations):\n",
        "        self.liklihood = 0\n",
        "        grad = [np.zeros((self.num_hidden, self.num_features)), np.zeros((self.num_classes, self.num_hidden)), np.zeros((self.num_classes, self.num_hidden, self.num_hidden)), np.zeros((2, self.num_classes, self.num_hidden, self.num_hidden))]\n",
        "        for i in range(size):\n",
        "            local_grad = self.local_gradient(self.convert_to_blocks(X[i]), y[i], num_LBP_iterations)\n",
        "            for j in range(4):\n",
        "                grad[j] += local_grad[j]\n",
        "        return grad\n",
        "   \n",
        "\n",
        "    def local_gradient(self, blocks, label, num_LBP_iterations):\n",
        "        grad = [np.zeros((self.num_hidden, self.num_features)), np.zeros((self.num_classes, self.num_hidden)), np.zeros((self.num_classes, self.num_hidden, self.num_hidden)), np.zeros((2, self.num_classes, self.num_hidden, self.num_hidden))]\n",
        "        self.LBP(num_LBP_iterations, blocks, label)\n",
        "        for loc, cluster in self.clusters['h'].items():\n",
        "            grad[0] += np.outer(cluster.belief, get_features(blocks[loc[0]][loc[1]]))\n",
        "            grad[1][label] = grad[1][label] + cluster.belief\n",
        "        for cluster in self.clusters['hhy'].values():\n",
        "            grad[2][label] += cluster.belief\n",
        "            if self.is_creative:\n",
        "                grad[3][cluster.is_ver][label] += cluster.belief\n",
        "        self.LBP(num_LBP_iterations, blocks)\n",
        "        self.liklihood += np.log(self.clusters['y'].belief[label])\n",
        "        for loc, cluster in self.clusters['hy'].items():\n",
        "            grad[0] -= np.outer(cluster.belief.sum(axis=0), get_features(blocks[loc[0]][loc[1]]))\n",
        "            grad[1] -= cluster.belief\n",
        "        for cluster in self.clusters['hhy'].values():\n",
        "            grad[2] -= cluster.belief\n",
        "            if self.is_creative:\n",
        "                grad[3][cluster.is_ver] += cluster.belief\n",
        "        return grad\n",
        "\n",
        "        \n",
        "    def LBP(self, num_iterations, blocks, label=None):\n",
        "        self.reset_messages()\n",
        "        self.set_params(self.params)\n",
        "        for i in range(self.num_blocks[0]):\n",
        "            for j in range(self.num_blocks[1]):\n",
        "                self.clusters['h'][(i, j)].set_pot_X(blocks[i][j])\n",
        "        if label is None:\n",
        "            for t in range(num_iterations):\n",
        "                y_cluster = self.clusters['y']\n",
        "                neighbors = set(y_cluster.prev_messages.keys())\n",
        "                for neighbor in neighbors:\n",
        "                    messages = y_cluster.pot\n",
        "                    other_neighbors = neighbors - set([neighbor])\n",
        "                    for other_neighbor in other_neighbors:\n",
        "                        neighbor_type = other_neighbor[0]\n",
        "                        neighbor_loc = other_neighbor[1]\n",
        "                        messages = messages * self.clusters[neighbor_type][neighbor_loc].messages['y']\n",
        "                    y_cluster.messages[neighbor] = normalize_factor(messages)\n",
        "                for loc, cluster in self.clusters['hy'].items():\n",
        "                    cluster.messages['y'] = normalize_factor(np.apply_along_axis(lambda x: x@self.clusters['h'][loc].messages[('hy', loc)], axis=1, arr=cluster.pot))                   \n",
        "                    cluster.messages[('h', loc)] = normalize_factor(np.apply_along_axis(lambda x: x@self.clusters['y'].messages[('hy', loc)], axis=0, arr=cluster.pot))\n",
        "                for loc, cluster in self.clusters['h'].items():\n",
        "                    neighbors = set(cluster.prev_messages.keys())\n",
        "                    for neighbor in neighbors:\n",
        "                        messages = cluster.pot\n",
        "                        other_neighbors = neighbors - set([neighbor])\n",
        "                        for other_neighbor in other_neighbors:\n",
        "                            neighbor_type = other_neighbor[0]\n",
        "                            neighbor_loc = other_neighbor[1]\n",
        "                            messages = messages * self.clusters[neighbor_type][neighbor_loc].messages[('h', loc)]\n",
        "                        cluster.messages[neighbor] = normalize_factor(messages)\n",
        "                for loc, cluster in self.clusters['hhy'].items():\n",
        "                    from_y = sum([self.clusters['y'].messages[('hhy', loc)][i] * cluster.pot[i,:,:] for i in range(self.num_classes)])\n",
        "                    to_y = sum([self.clusters['h'][loc[0]].messages[('hhy', loc)][i] * cluster.pot[:,i,:] for i in range(self.num_hidden)])\n",
        "                    cluster.messages['y'] = normalize_factor(sum([self.clusters['h'][loc[1]].messages[('hhy', loc)][i] * to_y[:,i] for i in range(self.num_hidden)]))\n",
        "                    for i_loc in [0, 1]:\n",
        "                        neighbor_recieve = self.clusters['h'][loc[1 - i_loc]].messages[('hhy', loc)]\n",
        "                        cluster.messages[('h', loc[i_loc])] = normalize_factor(np.apply_along_axis(lambda x: x@neighbor_recieve, axis=1 - i_loc, arr=from_y))\n",
        "                self.update_prev_messages()\n",
        "        else:\n",
        "            for loc, cluster in self.clusters['hy'].items():\n",
        "                cluster.set_pot_y(label)\n",
        "                cluster.prev_messages = cluster.messages = {('h', loc): cluster.pot}\n",
        "            for cluster in self.clusters['hhy'].values():\n",
        "                cluster.set_pot_y(label)\n",
        "                cluster.messages.pop('y')  \n",
        "            for t in range(num_iterations):\n",
        "                for loc, cluster in self.clusters['h'].items():\n",
        "                    neighbors = set(cluster.prev_messages.keys())\n",
        "                    for neighbor in neighbors:\n",
        "                        messages = cluster.pot\n",
        "                        other_neighbors = neighbors - set([neighbor])\n",
        "                        for other_neighbor in other_neighbors:\n",
        "                            neighbor_type = other_neighbor[0]\n",
        "                            neighbor_loc = other_neighbor[1]\n",
        "                            messages = messages * self.clusters[neighbor_type][neighbor_loc].messages[('h', loc)]\n",
        "                        cluster.messages[neighbor] = normalize_factor(messages)\n",
        "                for loc, cluster in self.clusters['hhy'].items():\n",
        "                    messages = self.clusters['y'].messages[('hhy', loc)]\n",
        "                    for i_loc in [0, 1]:\n",
        "                        neighbor_recieve = self.clusters['h'][loc[1 - i_loc]].messages[('hhy', loc)]\n",
        "                        messages = np.apply_along_axis(lambda x: x@neighbor_recieve, axis=1 - i_loc, arr=cluster.pot)\n",
        "                        neighbor = ('h', loc[i_loc])\n",
        "                        cluster.messages[neighbor] = normalize_factor(messages)\n",
        "                self.update_prev_messages()\n",
        "        is_y_None = label is None\n",
        "        self.calculate_belief(is_y_None)\n",
        "\n",
        "        \n",
        "    def calculate_belief(self, is_y_None):\n",
        "        for cluster in self.all_clusters:\n",
        "            cluster.calculate_belief(is_y_None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akO-EsFaQCud",
        "colab_type": "text"
      },
      "source": [
        "## Estimator Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03E_jNfyQCud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Estimator:\n",
        "    def __init__(self, est_type, genre_prior):\n",
        "        self.est_type = est_type\n",
        "        self.genre_prior = genre_prior\n",
        "        self.img_size = (44, 30)\n",
        "        if est_type == 'Horizontal':\n",
        "            self.num_blocks = (4, 1)\n",
        "        elif est_type == 'Vertical':\n",
        "            self.num_blocks = (1, 3)\n",
        "        elif est_type == 'Advanced' or est_type == 'Creative':\n",
        "            self.num_blocks = (4, 3)\n",
        "        self.num_hidden = 3\n",
        "        self.num_LBP_iterations = 8\n",
        "        self.num_GD_iterations = 50\n",
        "        self.cluster_graph = ClusterGraph(self.img_size, self.num_blocks, self.num_hidden, self.est_type, genre_prior, 2)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        results = []\n",
        "        proba = self.predict_proba(X)\n",
        "        for i in range(len(X)):\n",
        "            if proba[i][1] > proba[i][0]:\n",
        "                results.append(1)\n",
        "            else:\n",
        "                results.append(0)\n",
        "        return np.array(results)\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        size = len(X)\n",
        "        self.cluster_graph.gradient_ascent(X, y, size, self.num_LBP_iterations, self.num_GD_iterations)\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        results = []\n",
        "        for i, image in enumerate(X):\n",
        "            self.cluster_graph.LBP(self.num_LBP_iterations, self.cluster_graph.convert_to_blocks(image))\n",
        "            results.append(self.cluster_graph.clusters['y'].belief)\n",
        "        return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTaifSDrQCuf",
        "colab_type": "text"
      },
      "source": [
        "## Expermients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBeAMzcvQCug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "estimators = {'Horizontal': {}, 'Vertical': {}, 'Advanced': {}, 'Creative': {}}\n",
        "for est_type in estimators.keys():\n",
        "    pred = []\n",
        "    estimators[est_type]['estimators'] = []\n",
        "    for genre_index in range(y.shape[1]):\n",
        "        genre_prior = (y_train[:, genre_index].sum() / y_train[:, genre_index].shape[0])\n",
        "        est = Estimator(est_type, genre_prior)\n",
        "        est.fit(X_train, y_train[:, genre_index])\n",
        "        result = est.predict(X_test)\n",
        "        pred.append(result)\n",
        "        estimators[est_type]['estimators'].append((est, result))\n",
        "    pred = np.array(pred).T\n",
        "    estimators[est_type]['pred'] = pred\n",
        "    f1 = f1_score(y_true=y_test, y_pred=pred,average='weighted')\n",
        "    estimators[est_type]['f1'] = f1\n",
        "    print(est_type, ap, f1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}